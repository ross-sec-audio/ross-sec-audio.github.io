---
title: Vulnerability Management in 4 Stages
date: 2022-06-07
tags: [infosec, vulnerability]     # TAG names should always be lowercase
image:
  src: /assets/img/imgs/vuln-banner.jpg
  width: 1000   # in pixels
  height: 200   # in pixels
  alt: abstract banner
---

> Well, running a periodic Nessus scan on some of your organisation's stuff ain't it. 
{: .prompt-tip }

## What is Vulnerability Management?
It's a lifecycle of tools, team collaboration and processes, including: 
1. Periodic/continuous scanning of all your organisation's assets using various tools
2. Informed measurement and prioritisation of findings from these tools
3. The remediation of those findings through collaboration with various teams
4. The verification that those remediation actions worked 

5. Extra Bonus Stage - Doing it all again because it‚Äôs a continuous virtuous cycle

![Vulnerability Management Cycle](/assets/img/imgs/vuln-lifecycle.png)
_Vulnerability Management Cycle_

This blog post is a rant about each of these steps.

### Caveat
While I've some experience of setting up and running vulnerability management programmes, I'm in no way an expert and these are just my thoughts. If I've made any mistakes or omitted anything important I'd love to know. I'm keen to continually learn more üòÄ 

This is where I harp on about the importance of asset management as the foundation for all other InfoSec functions. 

## Coverage

If you don‚Äôt have a good understanding of your assets (e.g. your endpoint devices, mobile devices, servers, infrastructure components, code repos, data centres, 3rd party vendors, etc.), what their ‚Äúbill of materials‚Äù includes and how they're being used by your staff and customers, you‚Äôll struggle to secure them. 

The same goes for vulnerability management. If you‚Äôre only scanning a portion of your assets, you‚Äôll get a false sense of security when some tool reports that you have n number of critical vulnerabilities. 

Getting 100% coverage is hard though. It often requires multiple tools, each fulfilling a different function.

Examples of vulnerability tool types include:
- **Static Analysis Security Testing (SAST) solutions** - These search for vulnerabilities in your code base. OWASP includes a good list of SAST tools here: [https://owasp.org/www-community/Source_Code_Analysis_Tools](https://owasp.org/www-community/Source_Code_Analysis_Tools "https://owasp.org/www-community/Source_Code_Analysis_Tools")

- **Dynamic Analysis Security Testing (DAST) solutions** - These search for vulnerabilities in your applications during runtime. [OWASP ZAP](https://www.zaproxy.org/ "OWASP ZAP") is a full featured free and open source DAST tool.

- **Software Composition Analysis (SCA) solutions** - These search for vulnerabilities in open source packages and components that are included or imported into your applications (think Log4J). [Github](https://github.com/features/security/software-supply-chain "Github") & [Snyk](https://snyk.io/product/open-source-security-management/ "Snyk") both include easy to use SCA features.

- **Network Vulnerability Scanning solutions** - These scan networks and connected devices/servers for vulnerabilities. [OpenVAS](https://github.com/greenbone/openvas-scanner "OpenVAS") is a nice and flexible open source vulnerability scanner.

- **Interactive Application Security Testing (IAST) solutions** - Through installed agents, these test applications at runtime while analysing the relevant source code to identify more vulnerabilities with a lower rate of false positives. DZone has a great article going into further detail about IAST [here](https://dzone.com/refcardz/introduction-to-iast "here").

- **Pen. Testing** - an authorised security exercise where a cyber-security expert attempts to actively find and exploit vulnerabilities in an application.

These tools and methods can either be used as a part of a software development pipeline, to ensure that a deployed product is secure by design, or as an operational ‚Äúbusiness as usual‚Äù service, run by your security assurance team, to find and fix vulnerabilities in already existing and live assets.

I think the trick is to understand what assets your organisation already has in place and what they‚Äôre planning on developing/procuring in the near future. Then you can begin to explore various options to implement vulnerability management tooling or processes that fit your organisation's threats.

Ideally you‚Äôd want to scan everything all the time, but that's not always easy.

## Continuous scanning of everything

How realistic is this? It depends. But that caveat doesn't change the goal: You want to continually have an up to date picture of the security posture of all your assets. With that full picture you can prioritise effectively and reduce your organisation‚Äôs risk exposure.

My recommendation here is to go have a friendly and empathetic chat with your architecture, development, test and operations teams to figure out what will and won't work for them. 

This could include discussions about tooling that works for those teams, while also achieving adequate coverage. Ideally you don't want to ask a team to use tools they hate, so instead you could ask them to try a few and see what works for everyone.

One thing to keep in mind is the Load implications of running a vulnerability scanning tool continuously. Testing is key here as you‚Äôll need to identify what you can do without breaking your organisation's technology and processes. Again it‚Äôs recommended that you chat with relevant technical leads, so you don‚Äôt end up DoSing your own systems.

### Continuous scanning all the time, or every once in a while?

It's generally not recommended to only check for vulnerabilities in your assets once a year, but sometimes a periodic scan is the most pragmatic approach. If you can get that period to occur often, like once a month, you‚Äôll get lots of benefits. Firstly you‚Äôll get the obvious benefit of having more visibility as your assets change over time, but you‚Äôll also keep your architecture, development, test and operations teams happy (after the initial wave of vulnerabilities you find after the first scan üò≠). 

Instead of sharing a list of thousands of significant vulnerabilities once a year, you can continually work with teams and support them to address findings on an on-going basis. This allows them to bake remediation, configuration updates and patch management practices into their technical backlogs, business as usual workloads and capacity management.

## Prioritisation

After you some scans, you‚Äôll realise that you‚Äôve identified a significant vulnerabilities. While massively worrying and panic inducing, this is pretty common and and just requires some planning to confirm which vulnerabilities should be remediated and addressed first.

CVSS scores are incredibly useful in helping organisations to prioritise their vulnerabilities. They are derived from various metrics which can be used to help understand a given score's relevance in your own context. The following is a list of metrics used in CVSS v3.1:

### Base Score Metrics

| **Metric** | **Score** |
|---|--|
| **Attack Vector (AV)** | Network (AV:N), Adjacent Network (AV:A), Local (AV:L), Physical (AV:P) |
| **Attack Complexity (AC)** | Low (AC:L), High (AC:H) |
| **Privileges Required (PR)** | None (PR:N), Low (PR:L), High (PR:H) |
| **User Interaction (UI)** | None (UI:N), Required (UI:R) |
| **Scope (S)** | Unchanged (S:U), Changed (S:C) |  

### Impact Metrics

| **Metric** | **Score** |
|--|--|
| **Confidentiality Impact (C)** | None (C:N), Low (C:L), High (C:H) |
| **Integrity Impact (I)** | None (I:N), Low (I:L), High (I:H) |
| **Availability Impact (A)** | None (A:N), Low (A:L), High (A:H) |

### Temporal Score Metrics

| **Metric** | **Score** |
|--|--|
| **Exploit Code Maturity (E)** | Not Defined (E:X), Unproven that exploit exists (E:U), Proof of concept code (E:P), Functional exploit exists (E:F), High (E:H) |
| **Remediation Level (RL)** | Not Defined (RL:X), Official fix (RL:O), Temporary fix (RL:T), Workaround (RL:W), Unavailable (RL:U) |
| **Report Confidence (RC)** | Not Defined (RC:X), Unknown (RC:U), Reasonable (RC:R), Confirmed (RC:C) |

### Environmental Metrics

| **Metric** | **Score** |
|--|--|
| **Confidentiality Requirement (CR)** | None (C:N), Low (C:L), Medium (CR:M), High (C:H) |
| **Integrity Requirement (IR)** | None (I:N), Low (I:L), Medium (IR:M), High (I:H) |
| **Availability Requirement (AR)** | None (A:N), Low (A:L), Medium (AR:M), High (A:H) |

![Asset Meme](/assets/img/imgs/asset_meme.jpg){: .right w="250" h="400" }

CVSS v3.1 includes Environmental Metrics which enable your organisation to customise the CVSS score depending on the importance of the affected IT asset. This allows your organisation to take the business criticality, value and risk associated with a given asset into account when prioritising identified vulnerabilities.

However, this requires you to already have an agreed understanding of the business criticality, value and risk of all your assets. Having this full view of the whole world is difficult because differing parts of your organisation will probably disagree about each of those metrics.

[CVSS v3.1 Specification](https://www.first.org/cvss/specification-document "CVSS v3.1 Specification")

[NIST - CVSS v3 Calculator](https://nvd.nist.gov/vuln-metrics/cvss/v3-calculator "NIST - CVSS v3 Calculator")

Example: 
~~~
CVSS v3.1 Vector: AV:N/AC:L/PR:L/UI:R/S:U/C:H/I:H/A:L/E:F/RL:O/RC:C/CR:H/IR:H/AR:H/MAV:X/MAC:X/MPR:L/MUI:X/MS:X/MC:X/MI:X/MA:X
~~~

## Remediation

When a vulnerability is discovered on an asset, InfoSec teams, 99% of the time, are not the people doing the remediation work (patching/upgrading/reconfiguring). This means they need to work closely with architecture, development, test and operations teams in the hopes that they will fix the issues you‚Äôve found.

But we've the same issue here that helped to spawn the DevOps movement: Just as development and operations teams often used to not work well together, InfoSec teams continue to lack empathy and don‚Äôt collaborate well with other teams. We are often the "no" or obstacle team and in relation to identified vulnerabilities, we often recommend "just patching it". 

This is commonly due to a lack of understanding. For those InfoSec professionals who've never worked as developers, testers, system administrators or in an operations team, their only interaction with patching and upgrading will have been through end-user, commercially available software updates. 

Here, all the behind the scenes development, configuration work, testing and change advisory boards and documentation (the list goes on) is completed and all you need to do is press the update button. Even when running a simple server with a single function and little integration with its environment, patching is often not that simple. It comes with its own IT operational and availability (remember that old chestnut from the CIA triad?) risks that InfoSec teams need to understand and demonstrate empathy and understanding towards. Often a patch or upgrade doesn't even exist and the only option is a configuration change or the implementation of compensating security controls, while accepting the residual risk.

InfoSec teams should also understand that architecture, development, test and operations teams will already have long product and technical backlogs. Adding something new and expecting it to trump all the other stuff isn't grounded in reality.

Instead we need to build bridges with these teams through shared understanding. Not just through rephrasing InfoSec jargon, but through learning their craft, challenges, values and adapting our tooling/processes/people to fit their needs. We need pragmatism in our interactions and expectations of these teams. Compliance requirements that don't provide value should be challenged by the InfoSec team before they reach anyone else. And lastly we should support and stand up for these teams in our organisations for all the hard work they do.

## Verification and Continuous Improvement

I thought I was going to say a lot about this, but I think it all boils down to the following.

After the development, test and operations teams have remediated a vulnerability, it's the InfoSec team's responsibility to then verify that it's actually been fixed.

The easiest way to do this is to re-run the original test or scan.

Ideally, this should be done as an embedded part of the vulnerability remediation process, but rechecking for vulnerabilities should also occur through continuous scanning of all your assets.

If a fix hasn‚Äôt worked there‚Äôs probably a good reason so InfoSec teams need to be careful not to annoy or judge here. 

## Conclusion

I think the key takeaways from this blog are that: 

1. The entire lifecycle of vulnerabilities needs to be considered and carefully managed for you to make a useful difference.
2. Architecture, development, test and operations teams are on your side. They should be treated with respect for helping to fix the issues that you‚Äôve found.

### Go forth and be friendly üòÄ
